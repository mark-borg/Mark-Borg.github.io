---
layout: post
title:  AIMS2018 Presentation
tags:   
  - AI ethics
  - benevolent AI
  - AI bias
  - adversarial AI
  - value alignment
author: Mark Borg
image:  AIMS2018-keynote-presentation.png
---

&nbsp;

Last month I had the opportunity to deliver a keynote presentation at the [**AI Malta Summit (AIMS 2018)**](https://www.eventus-international.com/artificial-intelligence).
The subject of the presentation was on how we can train AI to be ethical and unbiased.

{{ more }}

Some of the topics covered included **Data Bias in AI** and some recent case studies of where such bias led to repercussions, and the very interesting topic of **AI Adversarial Attacks** and 
the contribution of **Generative Adversarial Networks (GANs)** in this area. 

On the ethics side, different ways were explored of how AI systems can be trained to be ethical. 

Of interest to **AI ethics** are **Reinforcement Learning (RL)** and **Inverse Reinforcement Learning (IRL)**, the same techniques that led to recent 
breakthroughs in AI such as in playing Go.

Finally, it is worth remembering that the current state-of-the-art in AI is based mostly on learning via data association and inductive reasoning (the first step on 
[Judea Pearl's **`ladder of causation'**](https://www.wsj.com/articles/ai-cant-reason-why-1526657442)).
Higher levels of reasoning (higher rungs on this metaphorical ladder) including reasoning via counterfactals are currently beyond the reach of modern AI. 
Achieving true artificial intelligence, especially of the benevolent type, will surely require such advanced AI. Hopefully when and if such a level is reached, the 
values of AI systems will be aligned with the value systems of humankind.


The slides of this presentation are [available on slideshare](https://www.slideshare.net/MarkBorg2/how-do-we-train-ai-to-be-ethical-and-unbiased).

[![Slideshare](/img/posts/AIMS2018-slideshare-presentation.png)](https://www.slideshare.net/MarkBorg2/how-do-we-train-ai-to-be-ethical-and-unbiased)


Comments are welcome.
